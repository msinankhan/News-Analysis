{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzBjoXSNVMzAVGqh2YxhCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msinankhan/News-Analysis/blob/main/News_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The following project is built with an intention to help in the analysis of the coverage of various media outlets.\n",
        "\n",
        "###We try to count the number of articles a given media has dedicated to a given topic.\n",
        "\n",
        "###We hypothesize that if the article is about a given subject, that words most likely exists in the title of the article.\n",
        "###As in the following case, we assume if the article is about covid, the words COVID or COVID-19 or CORONA VIRUS etc would be present in the title\n"
      ],
      "metadata": {
        "id": "QT3oQ5wW_R6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install newspaper3k"
      ],
      "metadata": {
        "id": "QUpGC-3NtHLN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Importing necessary packages..."
      ],
      "metadata": {
        "id": "3eXvu578-FqN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIds3NmBsiD4"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from bs4.dammit import EncodingDetector\n",
        "from newspaper import Article\n",
        "import requests\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL=[\"https://www.timesnownews.com/coronavirus\",\"https://www.indiatoday.in/coronavirus\",\"https://www.ndtv.com/coronavirus?pfrom=home-mainnavgation\"]\n",
        "Url_count = []"
      ],
      "metadata": {
        "id": "BXL3K92Dsq-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following for loop scrapres all the links that exist within a url from the URL list.\n",
        "\n",
        "Each of the extracted link's title is then printed"
      ],
      "metadata": {
        "id": "kj2OTodv-Pay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for url in URL:\n",
        "    parser = 'html.parser'  \n",
        "    resp = requests.get(url)\n",
        "    http_encoding = resp.encoding if 'charset' in resp.headers.get('content-type', '').lower() else None\n",
        "    html_encoding = EncodingDetector.find_declared_encoding(resp.content, is_html=True)\n",
        "    encoding = html_encoding or http_encoding\n",
        "    soup = BeautifulSoup(resp.content, parser, from_encoding=encoding)\n",
        "        \n",
        "    links = []\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        if \"javascript\" in link[\"href\"]:\n",
        "            continue\n",
        "        links.append(link['href'])\n",
        "    count = 0 \n",
        "    for link in links:\n",
        "        try:\n",
        "            article = Article(link)\n",
        "            article.download()\n",
        "            article.parse()\n",
        "            print(article.title)\n",
        "            if \"COVID\" in article.title or \"coronavirus\" in article.title or \"Coronavirus\"in article.title or \"Covid-19\" in article.title or \"COVID-19\" in article.title :\n",
        "                    count += 1\n",
        "    \n",
        "        except:\n",
        "            pass\n",
        "    Url_count.append(count)\n",
        "    print()\n",
        "    print()\n",
        "    print()"
      ],
      "metadata": {
        "id": "NcHfFCRKsq0Y",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code displays the number of occurances of a given word (\"covid\") in the title of each news website"
      ],
      "metadata": {
        "id": "ODxQnCzO-tZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1m'+ 'Number of articles with the word \"coronavirus\" in it' )    \n",
        "for url, count in zip(URL, Url_count):\n",
        "       \n",
        "    print('\\033[1m'+ \"Site:\", url, '\\033[1m'+ \"Count:\", count)\n",
        "    print()\n",
        "    print()\n",
        "print('\\033[1m'+'Graphical representation of the word count')"
      ],
      "metadata": {
        "id": "-34y47ajsqvr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the following code displays a bar graph showing the comparisions between different websites."
      ],
      "metadata": {
        "id": "rfMfBumw_A4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make an array for the x-axis from the URL List \n",
        "nx = np.arange(len(URL)) \n",
        "\n",
        "labels = ['timessnownews', 'indiatoday','Ndtv']\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca()\n",
        "ax.set_title('Media analysis')\n",
        "ax.bar(nx, Url_count)\n",
        "ax.set_xticks(nx)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_ylabel('Number of articles')\n",
        "ax.set_xlabel('News Websites')"
      ],
      "metadata": {
        "id": "VkZOb3gnsqsi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}